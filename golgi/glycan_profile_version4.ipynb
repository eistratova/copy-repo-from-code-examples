{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## generate glycan profile for a given distribution of enzymes\n",
    "\n",
    "## TO DO:\n",
    "## use of function to \n",
    "##      1. randomly select the distribution of enzymes in a compartment - DONE\n",
    "##      2. getting glycan profile for the selected enzyme distribution - DONE\n",
    "## add extra condition to avoid beyond 2 branches (see if this is required ?)\n",
    "## elegant way to print the tree                                       - DONE\n",
    "## also, this generates only 1 product - modify to generate all the products - DONE\n",
    "\n",
    "\n",
    "# how to generate a graph or tree in python\n",
    "# https://www.geeksforgeeks.org/generate-graph-using-dictionary-python/\n",
    "\n",
    "# https://stackoverflow.com/questions/1602934/check-if-a-given-key-already-exists-in-a-dictionary\n",
    "# https://stackoverflow.com/questions/3199171/append-multiple-values-for-one-key-in-python-dictionary\n",
    "\n",
    "# find all possible subgraphs of a graph in python\n",
    "# find all sub-graphs starting from root node in a directed tree/graph in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## step 1: generate all possible binary combinations of 8 digits (corresponding to 8 enzymes)\n",
    "#https://stackoverflow.com/questions/14931769/how-to-get-all-combination-of-n-binary-value\n",
    "\n",
    "import itertools\n",
    "\n",
    "num_enzymes = 7 #8\n",
    "# since the first enzyme should be present in the 1st compartment & not in later compartments,\n",
    "# we can leave this out for now\n",
    "\n",
    "lst = map(list, itertools.product([0, 1], repeat = num_enzymes))\n",
    "#lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### mapping file for all enzyme reactions ####\n",
    "\n",
    "#P/0 -> A/1 (yellow sq) -> B/2 (blue sq)   -> C/3 (red tri)\n",
    "#  1                    2                3\n",
    "\n",
    "#p ->   A/1 (yellow sq) -> D/4 (yellow cr) -> B/2 (blue sq)\n",
    "#                       4                5\n",
    "                      \n",
    "#------------------------  D/4 (yellow cr) -> E/5 (brown diamond)\n",
    "#                                       6\n",
    "                                     \n",
    "#------------------------  B/2 (blue sq)   -> D/4 (yellow cr)\n",
    "#                                       7\n",
    "\n",
    "#-----  A/1 (yellow sq) -> E/5 (brown rhombus)\n",
    "#                       8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a 2D array with the sequence: enzyme no, 1st substrate, 2nd substrate\n",
    "map = []\n",
    "# map.append([1,0,1])   # leave out the first enzyme\n",
    "map.append([2,1,2])\n",
    "map.append([4,1,4])\n",
    "map.append([8,1,5])\n",
    "map.append([3,2,3])\n",
    "map.append([7,2,4]) # these 2 enzymes being present in the same compartment will give rise to cyclisation\n",
    "map.append([5,4,2]) # eliminate correponding combinations from the master_list at the very beginning ?\n",
    "map.append([6,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intialise the sugar as a dictionary\n",
    "mol = {'1_1':''}  # sugarname_position; the keys are in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# foreach item in the above list (of enzyme distribution), if value=1, select the corresponding reaction index from map\n",
    "# then check if existing glycan list already contains sugars to which the new ones can be appended;\n",
    "# allow branching where possible : add extra condition to avoid beyond 2 branches\n",
    "\n",
    "def get_gly(cnt,comp_distr,mol,nodeName):   # cnt,num_enzymes,map\n",
    "    \n",
    "    # select enzyme distribution\n",
    "    #comp_distr = random.choice(lst)\n",
    "    #comp_distr = [0, 0, 1, 0, 0, 1, 1]   ## comp 1\n",
    "    #comp_distr = [1, 1, 0, 0, 0, 1, 0]   ## comp 2\n",
    "    #comp_distr = [1, 1, 0, 1, 1, 0, 0]    ## comp 3\n",
    "    #print(comp_distr)\n",
    "    \n",
    "    # get glycan\n",
    "    for i in range(num_enzymes): #since, len(comp_distr) = num_enzymes\n",
    "        if comp_distr[i]==1:\n",
    "            #print('')    #print(map[i])\n",
    "            \n",
    "            # check if the left element of the selected reaction is already present in the glycan chain\n",
    "            for k in range(1,cnt):  # this indicates values from 1 to cnt-1\n",
    "                #print(k)   #print(str(map[i][1])+'_'+str(k))\n",
    "                if (str(map[i][1])+'_'+str(k)) in mol:\n",
    "                    mol[(str(map[i][1])+'_'+str(k))] = (mol[(str(map[i][1])+'_'+str(k))] + ', '+ str(map[i][2]) + '_' + str(k+1))  \n",
    "                    #mol[(str(map[i][2])+'_'+str(k+1))] = ''\n",
    "                    \n",
    "                    nodeName[(str(map[i][1])+'_'+str(k))] = ''\n",
    "                    nodeName[(str(map[i][2])+'_'+str(k+1))]= ''\n",
    "                    \n",
    "                    if(str(map[i][2])+'_'+str(k+1)) in mol:\n",
    "                        mol[str(map[i][2])+'_'+str(k+1)] = mol[str(map[i][2])+'_'+str(k+1)]\n",
    "                    else:\n",
    "                        mol[(str(map[i][2])+'_'+str(k+1))] = ''\n",
    "                    cnt = cnt+1\n",
    "                \n",
    "    return (mol,cnt,nodeName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################  compartment 1  #########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "#comp_distr = random.choice(lst)\n",
    "comp_distr = [0, 0, 1, 0, 0, 1, 1]\n",
    "nodeName={}\n",
    "\n",
    "mol,Cnt,nodeName = get_gly(2,comp_distr,mol,nodeName)     # 2,num_enzymes,map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_2->\n",
      "1_1->, 5_2\n"
     ]
    }
   ],
   "source": [
    "for key in mol:\n",
    "    print(key + '->' + mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# compartment 2 #####################\n",
    "#comp_distr = random.choice(lst)\n",
    "comp_distr = [1, 1, 0, 0, 0, 1, 0] \n",
    "\n",
    "mol,Cnt,nodeName = get_gly(Cnt,comp_distr,mol,nodeName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2->, 2_3\n",
      "5_2->\n",
      "2_2->\n",
      "2_3->\n",
      "1_1->, 5_2, 2_2, 4_2\n"
     ]
    }
   ],
   "source": [
    "for key in mol:\n",
    "    print(key + '->' + mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# compartment 3 #####################\n",
    "#comp_distr = random.choice(lst)\n",
    "comp_distr = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "mol,Cnt,nodeName = get_gly(Cnt,comp_distr,mol,nodeName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_3->\n",
      "3_4->\n",
      "2_2->, 3_3, 4_3\n",
      "2_3->, 3_4, 4_4\n",
      "5_2->\n",
      "1_1->, 5_2, 2_2, 4_2, 2_2, 4_2\n",
      "4_2->, 2_3\n",
      "4_3->\n",
      "4_4->\n"
     ]
    }
   ],
   "source": [
    "for key in mol:\n",
    "    print(key + '->' + mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "## generate the product profile at the end\n",
    "# STEPS: \n",
    "# clean-up : remove keys with no value assigned\n",
    "# consider sub-graphs which include only the key 1_1 (root node), but not those with contain only 2_2 or 2_3\n",
    "#                                    (since these cant start assembly)\n",
    "# consider all valid combinations\n",
    "\n",
    "\n",
    "# or, generate the tree using this link : https://www.geeksforgeeks.org/generate-graph-using-dictionary-python/\n",
    "# so that clean-up is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2->, 2_3\n",
      "2_2->, 3_3, 4_3\n",
      "2_3->, 3_4, 4_4\n",
      "1_1->, 5_2, 2_2, 4_2, 2_2, 4_2\n"
     ]
    }
   ],
   "source": [
    "# clean-up : remove keys with no value assigned\n",
    "clean_mol = dict([(vkey, vdata) for vkey, vdata in mol.iteritems() if(str(vdata).strip()) ])\n",
    "\n",
    "for key in clean_mol:\n",
    "    print(key + '->' + clean_mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2-> 2_3\n",
      "2_2-> 4_3 3_3\n",
      "2_3-> 3_4 4_4\n",
      "1_1-> 4_2 5_2 2_2\n"
     ]
    }
   ],
   "source": [
    "# clean-up : remove ', ' at the beginning by using [2:], split by ', ', & then remove repetitions in the values\n",
    "for key in clean_mol:\n",
    "    clean_mol[key] =  ' '.join(list(set(clean_mol[key][2:].split(', ')))) # list(set(mol['1_1'][2:].split(', ')))\n",
    "\n",
    "for key in clean_mol:\n",
    "    print(key + '-> ' + clean_mol[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3_3': '', '3_4': '', '2_2': '', '2_3': '', '5_2': '', '1_1': '', '4_2': '', '4_3': '', '4_4': ''}\n",
      "\n",
      "no.of nodes:9\n"
     ]
    }
   ],
   "source": [
    "# count no of nodes in the tree\n",
    "\n",
    "print(nodeName)\n",
    "print('')\n",
    "print('no.of nodes:' + str(len(nodeName)))\n",
    "#print(nodeName[0])\n",
    "#print(nodeName[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print valid sub-graphs starting from root note 1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2 2_3\n",
      "2_2 4_3\n",
      "2_2 3_3\n",
      "2_3 3_4\n",
      "2_3 4_4\n",
      "1_1 4_2\n",
      "1_1 5_2\n",
      "1_1 2_2\n"
     ]
    }
   ],
   "source": [
    "# save molecule as graph\n",
    "g = nx.Graph()\n",
    "\n",
    "for key in clean_mol:\n",
    "    # split the nodes attached to each key\n",
    "    conn_node = clean_mol[key].split(' ')\n",
    "    \n",
    "    for j in range(0, len(conn_node)):\n",
    "        g.add_edge(key, conn_node[j])\n",
    "        print(str(key)+' '+str(conn_node[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22180410/how-can-i-extract-all-possible-induced-subgraphs-from-a-given-graph-with-network\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_subgraph(s):\n",
    "    target = nx.complete_graph(s)\n",
    "    for sub_nodes in itertools.combinations(g.nodes(),len(target.nodes())):\n",
    "        subg = g.subgraph(sub_nodes)\n",
    "        #print(subg.dtype)  #\n",
    "        if nx.is_connected(subg) and '1_1' in str(subg.edges()):\n",
    "            print subg.edges()\n",
    "            #print subg.edges('1_1')\n",
    "            #(subg.edges()).dtype\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2_2', '1_1')]\n",
      "[('5_2', '1_1')]\n",
      "[('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('2_2', '1_1')]\n",
      "[('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1')]\n",
      "[('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('5_2', '1_1'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print all sub-trees containing '1_1'\n",
    "for j in range(1, len(nodeName)):  # or, use len(g.nodes)\n",
    "    get_subgraph(j+1)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "####  NOT NEEDED ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Edges in g: ', EdgeDataView([('3_3', '2_2', {}), ('3_4', '2_3', {}), ('2_2', '4_3', {}), ('2_2', '1_1', {}), ('2_3', '4_2', {}), ('2_3', '4_4', {}), ('5_2', '1_1', {}), ('1_1', '4_2', {})]))\n"
     ]
    }
   ],
   "source": [
    "#print(\"Edges in g: \", g.edges(data=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_1': ['1_1'],\n",
       " '2_2': ['1_1', '2_2'],\n",
       " '2_3': ['1_1', '4_2', '2_3'],\n",
       " '3_3': ['1_1', '2_2', '3_3'],\n",
       " '3_4': ['1_1', '4_2', '2_3', '3_4'],\n",
       " '4_2': ['1_1', '4_2'],\n",
       " '4_3': ['1_1', '2_2', '4_3'],\n",
       " '4_4': ['1_1', '4_2', '2_3', '4_4'],\n",
       " '5_2': ['1_1', '5_2']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# https://groups.google.com/forum/#!topic/networkx-discuss/UCmplWkZM3M\n",
    "def graphtodepth(g,root,depth):\n",
    "    link_set = set()\n",
    "    traversed = set()\n",
    "    rootset = set([root])\n",
    "    while (depth >= 0) and (rootset):\n",
    "        newrootset = set()\n",
    "        for d in rootset:\n",
    "            traversed.add(d)\n",
    "            neighbors = g.neighbors(d)\n",
    "            nextlinks = [(d,n) for n in neighbors]\n",
    "            newrootset = newrootset.union(set(neighbors)) - traversed\n",
    "            link_set = link_set.union(nextlinks)\n",
    "        rootset = newrootset\n",
    "        depth -= 1\n",
    "    return nx.Graph(list(link_set)) \n",
    "\n",
    "\n",
    "# graphtodepth(g,'1_1',2).edges()\n",
    "nx.single_source_shortest_path(g,'1_1',cutoff=3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22180410/how-can-i-extract-all-possible-induced-subgraphs-from-a-given-graph-with-network\n",
    "\n",
    "import itertools\n",
    "\n",
    "def get_subgraph(s):\n",
    "    target = nx.complete_graph(s)\n",
    "    for sub_nodes in itertools.combinations(g.nodes(),len(target.nodes())):\n",
    "        subg = g.subgraph(sub_nodes)\n",
    "        #print(subg.dtype)  #\n",
    "        if nx.is_connected(subg):  # and '1_1' in str(subg.edges()):\n",
    "            print subg.edges()\n",
    "            #print subg.edges('1_1')\n",
    "            #(subg.edges()).dtype\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2')]\n",
      "[('3_4', '2_3')]\n",
      "[('2_2', '1_1')]\n",
      "[('2_2', '4_3')]\n",
      "[('2_3', '4_2')]\n",
      "[('2_3', '4_4')]\n",
      "[('5_2', '1_1')]\n",
      "[('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('2_2', '1_1')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_4')]\n",
      "[('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1')]\n",
      "[('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('2_3', '4_4')]\n",
      "[('5_2', '1_1'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('2_3', '4_4')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('1_1', '4_2')]\n",
      "[('3_3', '2_2'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n",
      "[('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3_3', '2_2'), ('3_4', '2_3'), ('2_2', '4_3'), ('2_2', '1_1'), ('2_3', '4_2'), ('2_3', '4_4'), ('5_2', '1_1'), ('1_1', '4_2')]\n"
     ]
    }
   ],
   "source": [
    "get_subgraph(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50885343/how-to-extract-all-sub-graphs-containing-a-specified-node-from-a-directed-graph\n",
    "\n",
    "# https://stackoverflow.com/questions/21739569/finding-separate-graphs-within-a-graph-object-in-networkx\n",
    "# https://stackoverflow.com/questions/22180410/how-can-i-extract-all-possible-induced-subgraphs-from-a-given-graph-with-network\n",
    "# https://stackoverflow.com/questions/13914920/networkx-extract-the-connected-component-containing-a-given-node-directed-grap\n",
    "# https://stackoverflow.com/questions/18643789/how-to-find-subgraphs-in-a-directed-graph-without-converting-to-undirected-graph\n",
    "# https://stackoverflow.com/questions/40284774/efficient-way-for-finding-all-the-complete-subgraphs-of-a-given-graph-python\n",
    "\n",
    "\n",
    "# https://networkx.github.io/documentation/stable/auto_examples/subclass/plot_printgraph.html\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/16150557/networkxcreating-a-subgraph-induced-from-edges\n",
    "# https://stackoverflow.com/questions/47892944/python-networkx-find-a-subgraph-in-a-directed-graph-from-a-node-as-root?rq=1\n",
    "# https://stackoverflow.com/questions/36488758/networkx-find-root-node-for-a-particular-node-in-a-directed-graph\n",
    "# https://stackoverflow.com/questions/18843247/find-the-root-in-a-given-graph\n",
    "\n",
    "# google:\n",
    "# depth first search in networkx\n",
    "# find all subgraphs containing a specified node in a directed graph in python\n",
    "# networkX root node to leaf node\n",
    "# how to extract all subgraphs containing a specified node from a given directed graph\n",
    "# stackoverflow find sub graph with root node from tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# https://stackoverflow.com/questions/7134742/python-yield-all-paths-from-leaves-to-root-in-a-tree\n",
    "# https://anandology.com/python-practice-book/iterators.html\n",
    "# https://jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/\n",
    "\n",
    "def paths(self, acc=[]):\n",
    "    if self.is_leaf():\n",
    "        yield [self.node]+acc\n",
    "\n",
    "    for child in self.children:\n",
    "        for leaf_path in child.paths([self.node]+acc): # these two\n",
    "            yield leaf_path                            # lines do that  \n",
    "            \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
