{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive thres + dilate-erode + open/close\n",
    "\n",
    "def Hough_transform(filename,outimg, outmask):\n",
    "    start_time=time.time()\n",
    "    image = cv2.imread(filename)  \n",
    "    print(\" read time: %s seconds \" % (time.time() - start_time)) \n",
    "    \n",
    "    h, w, c = image.shape\n",
    "    \n",
    "    # resize large images\n",
    "    if h>512:\n",
    "        scale_percent = 30 # percent of original size\n",
    "        w = int(image.shape[1] * scale_percent / 100)\n",
    "        h = int(image.shape[0] * scale_percent / 100)\n",
    "        dim = (w, h)\n",
    "        # resize image\n",
    "        image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    mindist = int(min(h,w) * 0.8)\n",
    "    \n",
    "    \n",
    "    # keep copy of input image for final view\n",
    "    output = image.copy()\n",
    "    orig = image.copy()\n",
    "    \n",
    "    \n",
    "    # convert image to grayscale for processing\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # apply GuassianBlur to reduce noise. medianBlur is also added for smoothening, reducing noise.\n",
    "    gray_blur = cv2.medianBlur(gray,9)\n",
    "    #gray = cv2.medianBlur(gray,7)\n",
    "    #gray = cv2.GaussianBlur(gray,(3,3),0)  # the tuple is the gaussian Kernel : controls the amount of blurring\n",
    "    \n",
    "    # threshold\n",
    "    gray_thres = cv2.adaptiveThreshold(gray_blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,3.5)\n",
    "    #ret3,gray_thres = cv2.threshold(gray_blur,50,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU) # Otsu\n",
    "    \n",
    "    \n",
    "    # erosion-dilation\n",
    "    #gray_e = cv2.erode(gray_thres,None,iterations = 3)\n",
    "    #gray_d = cv2.dilate(gray_e,None,iterations = 3)\n",
    "    # dilation-erosion\n",
    "    gray_d = cv2.dilate(gray_thres,None,iterations = 1)\n",
    "    gray_e = cv2.erode(gray_d,None,iterations = 1)\n",
    "    #kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n",
    "    #gray_d = cv2.dilate(gray_thres,kernel1,iterations = 1)\n",
    "    #gray_e = cv2.erode(gray_d,kernel1,iterations = 1)\n",
    "    \n",
    "    # hole filling\n",
    "    kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11)) #(11,11)  (15,15)  (9,9)\n",
    "    #close = cv2.morphologyEx(gray_e,cv2.MORPH_CLOSE,kernel1)\n",
    "    # the closing operation adds white pixels; since the well boundary is black, it is breaking up,\n",
    "    # need to use open operation instead\n",
    "    close = cv2.morphologyEx(gray_e,cv2.MORPH_OPEN,kernel1)\n",
    "    #close = cv2.morphologyEx(gray_thres,cv2.MORPH_OPEN,kernel1)\n",
    "    \n",
    "    # flood-fill\n",
    "    #mask = np.zeros((h+2, w+2), np.uint8)\n",
    "    #im_floodfill = close.copy()\n",
    "    #cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    "    #im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "                                       \n",
    "    \n",
    "    # modify the parameters for houghtransform & retry    \n",
    "    #circles = cv2.HoughCircles(gray_e, cv2.HOUGH_GRADIENT, 2, mindist)#, param1=30, param2=65, minRadius=0, maxRadius=500)\n",
    "    circles = cv2.HoughCircles(close, cv2.HOUGH_GRADIENT, 2, mindist)#, param1=30, param2=65, minRadius=0, maxRadius=500)\n",
    "    #circles = cv2.HoughCircles(im_floodfill_inv, cv2.HOUGH_GRADIENT, 2, mindist)#, param1=30, param2=65, minRadius=0, maxRadius=500)\n",
    "\n",
    "    \n",
    "    # create mask file\n",
    "    #circle_image = np.zeros((h, w), dtype=\"uint8\") #dtype=image.dtype)\n",
    "    circle_image = np.zeros((h, w)) \n",
    "    #cv2.circle(circle_image, (int(w/2),int(h/2)), r, 255, -1)\n",
    "    \n",
    "    \n",
    "    # ensure at least some circles were found\n",
    "    if circles is not None:\n",
    "        # convert the (x, y) coordinates and radius of the circles to integers\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        \n",
    "        # loop over the (x, y) coordinates and radius of the circles\n",
    "        for (x, y, r) in circles:\n",
    "            # draw the circle in the output image, then draw a rectangle\n",
    "            # corresponding to the center of the circle\n",
    "            cv2.circle(output, (x, y), r, (0, 255, 0), 4)\n",
    "            cv2.rectangle(output, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    "            #cv2.circle(circle_image, (x,y), r, 255, -1)\n",
    "            cv2.circle(circle_image, (x,y), r, 1, -1)\n",
    "        \n",
    "        # show the output image\n",
    "        #cv2.imshow(\"output\", np.hstack([image, output]))\n",
    "        #cv2.waitKey(0)\n",
    "        #showimage(output)\n",
    "        #cv2.imwrite(outfile, output)   \n",
    "        \n",
    "    #else:\n",
    "    #    cv2.imwrite(outfile, output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # replace the white pixels with 1, to avoid a 2ns round of encoding\n",
    "    #result1 = circle_image.copy()\n",
    "    #result1[circle_image > 0] = 1  # !=0\n",
    "    #result1[circle_image <= 0] = 0\n",
    "    #_, result1 = cv2.threshold(circle_image, thresh=180, maxval=255, type=cv2.THRESH_BINARY)\n",
    "        \n",
    "        \n",
    "    # Make the grey scale image have three channels\n",
    "    #circle_image3 = cv2.cvtColor(circle_image, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    \n",
    "    # concatenate the images\n",
    "    #numpy_horizontal_concat = np.concatenate((gray_thres3, gray_d3, gray_e3, output), axis=1)\n",
    "    #numpy_horizontal_concat = np.concatenate((gray_thres3, close3, output), axis=1)\n",
    "    #numpy_horizontal_concat = np.concatenate((orig, circle_image3, output), axis=1)\n",
    "    cv2.imwrite(outimg, orig)\n",
    "    cv2.imwrite(outmask, circle_image) #circle_image)  result1\n",
    "    np.savetxt('mask_file.txt', circle_image)\n",
    "    \n",
    "    print(\" Inference time: %s seconds \" % (time.time() - start_time)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate masks with a subset of images\n",
    "\n",
    "image_List=[]\n",
    "with open((\"sample_filelist_mask.txt\"),'r') as fobj:\n",
    "    for line in fobj:\n",
    "        #print(line)\n",
    "        image_List.append(line.rstrip(\"\\n\"))\n",
    "fobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = \"C:/Users/data/Segment/images/\"\n",
    "out2 = \"C:/Users/data/Segment/masks/\"\n",
    "\n",
    "#os.mkdir(\"C:/Users/data/Segment/\")\n",
    "#os.mkdir(out1)\n",
    "#os.mkdir(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forums.fast.ai/t/saving-binary-mask-opens-as-a-trinary-mask-why/51648\n",
    "\n",
    ".jpg is a lossy format & may alter values.\n",
    "use a non-lossy format for masks where exact pixel values are important.\n",
    "Save the mask file as .png or .bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read time: 0.05443716049194336 seconds \n",
      " Inference time: 0.6363122463226318 seconds \n",
      " read time: 0.016956090927124023 seconds \n",
      " Inference time: 0.7933368682861328 seconds \n",
      " read time: 0.021940946578979492 seconds \n",
      " Inference time: 0.6163909435272217 seconds \n",
      " read time: 0.022994279861450195 seconds \n",
      " Inference time: 0.7430713176727295 seconds \n",
      " read time: 0.01695394515991211 seconds \n",
      " Inference time: 1.7688322067260742 seconds \n",
      " read time: 0.020943880081176758 seconds \n",
      " Inference time: 0.6120867729187012 seconds \n",
      " read time: 0.016955137252807617 seconds \n",
      " Inference time: 0.7292253971099854 seconds \n",
      " read time: 0.023014068603515625 seconds \n",
      " Inference time: 0.8021647930145264 seconds \n",
      " read time: 0.04340815544128418 seconds \n",
      " Inference time: 0.7913572788238525 seconds \n",
      " read time: 0.02678203582763672 seconds \n",
      " Inference time: 0.6666405200958252 seconds \n",
      " read time: 0.02198314666748047 seconds \n",
      " Inference time: 1.4545745849609375 seconds \n",
      " read time: 0.028471946716308594 seconds \n",
      " Inference time: 1.0232324600219727 seconds \n",
      " read time: 0.03238630294799805 seconds \n",
      " Inference time: 0.8067944049835205 seconds \n",
      " read time: 0.022023439407348633 seconds \n",
      " Inference time: 0.5722393989562988 seconds \n",
      " read time: 0.013018608093261719 seconds \n",
      " Inference time: 0.7466976642608643 seconds \n",
      " read time: 0.018950700759887695 seconds \n",
      " Inference time: 0.654130220413208 seconds \n",
      " read time: 0.022937536239624023 seconds \n",
      " Inference time: 0.6931166648864746 seconds \n",
      " read time: 0.020092248916625977 seconds \n",
      " Inference time: 1.0971128940582275 seconds \n",
      " read time: 0.02293992042541504 seconds \n",
      " Inference time: 1.6081821918487549 seconds \n",
      " read time: 0.02094101905822754 seconds \n",
      " Inference time: 1.2897934913635254 seconds \n",
      " read time: 0.020405054092407227 seconds \n",
      " Inference time: 1.1737937927246094 seconds \n",
      " read time: 0.01698756217956543 seconds \n",
      " Inference time: 1.2605621814727783 seconds \n",
      " read time: 0.01795482635498047 seconds \n",
      " Inference time: 0.621636152267456 seconds \n",
      " read time: 0.02996230125427246 seconds \n",
      " Inference time: 1.4469983577728271 seconds \n",
      " read time: 0.02203965187072754 seconds \n",
      " Inference time: 0.5490179061889648 seconds \n",
      " read time: 0.016744375228881836 seconds \n",
      " Inference time: 0.5538887977600098 seconds \n",
      " read time: 0.015989065170288086 seconds \n",
      " Inference time: 1.732985019683838 seconds \n",
      " read time: 0.022940635681152344 seconds \n",
      " Inference time: 0.7140336036682129 seconds \n",
      " read time: 0.032997846603393555 seconds \n",
      " Inference time: 1.0334827899932861 seconds \n",
      " read time: 0.024370193481445312 seconds \n",
      " Inference time: 0.789884090423584 seconds \n"
     ]
    }
   ],
   "source": [
    "d = 0\n",
    "\n",
    "for image in image_List:\n",
    "    #print(d) #,image)\n",
    "    outimg = out1 + \"image_\" + str(d) + \".jpg\"\n",
    "    outmask = out2 + \"mask_image_\" + str(d) + \".png\"\n",
    "    Hough_transform(image,outimg,outmask)   \n",
    "    d = d+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
