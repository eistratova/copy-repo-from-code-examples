{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary classification: crack vs no crack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"./\")\n",
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# opening the zip file in READ mode \n",
    "with ZipFile(\"ml.zip\", 'r') as zip: \n",
    "    # printing all the contents of the zip file \n",
    "    #zip.printdir() \n",
    "  \n",
    "    # extracting all the files \n",
    "    print('Extracting all the files now...') \n",
    "    zip.extractall() \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def get_image_spec(im_paths):\n",
    "    path_sorted = sorted([x for x in im_paths])\n",
    "    all_mode = []\n",
    "    \n",
    "    for idx in range(len(path_sorted)):\n",
    "        im_path = path_sorted[idx]\n",
    "        img = Image.open(im_path)\n",
    "        width, height = img.size\n",
    "        m = img.mode\n",
    "        #all_size[str(width) + '_' + str(height)] = ''  # saving height width as keys of dict\n",
    "        all_mode.append([im_path,m, width, height])\n",
    "        \n",
    "    all_mode = pd.DataFrame(all_mode, columns=['path','mode', 'width','height'])\n",
    "    return all_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image size\n",
    "\n",
    "im_paths = pathlib.Path('./ml/').glob('*/*/*')\n",
    "image_data = get_image_spec(im_paths)\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df with unique width & height,\n",
    "df = image_data.drop_duplicates(['width','height'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data.drop_duplicates(['mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-updating\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import fastai\n",
    "import time\n",
    "from fastai.vision import *\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradCAM\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "import scipy.ndimage\n",
    "\n",
    "class GradCam():\n",
    "    @classmethod\n",
    "    def from_interp(cls,learn,interp,img_idx,ds_type=DatasetType.Valid,include_label=False):\n",
    "        # produce heatmap and xb_grad for pred label (and actual label if include_label is True)\n",
    "        if ds_type == DatasetType.Valid:\n",
    "            ds = interp.data.valid_ds\n",
    "        elif ds_type == DatasetType.Test:\n",
    "            ds = interp.data.test_ds\n",
    "            include_label=False\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "        x_img = ds.x[img_idx]\n",
    "        xb,_ = interp.data.one_item(x_img)\n",
    "        xb_img = Image(interp.data.denorm(xb)[0])\n",
    "        probs = interp.preds[img_idx].numpy()\n",
    "\n",
    "        pred_idx = interp.pred_class[img_idx].item() # get class idx of img prediction label\n",
    "        hmap_pred,xb_grad_pred = get_grad_heatmap(learn,xb,pred_idx,size=xb_img.shape[-1])\n",
    "        prob_pred = probs[pred_idx]\n",
    "        \n",
    "        actual_args=None\n",
    "        if include_label:\n",
    "            actual_idx = ds.y.items[img_idx] # get class idx of img actual label\n",
    "            if actual_idx!=pred_idx:\n",
    "                hmap_actual,xb_grad_actual = get_grad_heatmap(learn,xb,actual_idx,size=xb_img.shape[-1])\n",
    "                prob_actual = probs[actual_idx]\n",
    "                actual_args=[interp.data.classes[actual_idx],prob_actual,hmap_actual,xb_grad_actual]\n",
    "        \n",
    "        return cls(xb_img,interp.data.classes[pred_idx],prob_pred,hmap_pred,xb_grad_pred,actual_args)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_one_img(cls,learn,x_img,label1=None,label2=None):\n",
    "        '''\n",
    "        learn: fastai's Learner\n",
    "        x_img: fastai.vision.image.Image\n",
    "        label1: generate heatmap according to this label. If None, this wil be the label with highest probability from the model\n",
    "        label2: generate additional heatmap according to this label\n",
    "        '''\n",
    "        pred_class,pred_idx,probs = learn.predict(x_img)\n",
    "        label1= str(pred_class) if not label1 else label1\n",
    "        \n",
    "        xb,_ = learn.data.one_item(x_img)\n",
    "        xb_img = Image(learn.data.denorm(xb)[0])\n",
    "        probs = probs.numpy()\n",
    "        \n",
    "        label1_idx = learn.data.classes.index(label1)\n",
    "        hmap1,xb_grad1 = get_grad_heatmap(learn,xb,label1_idx,size=xb_img.shape[-1])\n",
    "        prob1 = probs[label1_idx]\n",
    "        \n",
    "        label2_args = None\n",
    "        if label2:\n",
    "            label2_idx = learn.data.classes.index(label2)\n",
    "            hmap2,xb_grad2 = get_grad_heatmap(learn,xb,label2_idx,size=xb_img.shape[-1])\n",
    "            prob2 = probs[label2_idx]\n",
    "            label2_args = [label2,prob2,hmap2,xb_grad2]\n",
    "            \n",
    "        return cls(xb_img,label1,prob1,hmap1,xb_grad1,label2_args)\n",
    "    \n",
    "    def __init__(self,xb_img,label1,prob1,hmap1,xb_grad1,label2_args=None):\n",
    "        self.xb_img=xb_img\n",
    "        self.label1,self.prob1,self.hmap1,self.xb_grad1 = label1,prob1,hmap1,xb_grad1\n",
    "        if label2_args:\n",
    "            self.label2,self.prob2,self.hmap2,self.xb_grad2 = label2_args\n",
    "            \n",
    "    def plot(self,plot_hm=True,plot_gbp=True):\n",
    "        if not plot_hm and not plot_gbp:\n",
    "            plot_hm=True\n",
    "        cols = 5 if hasattr(self, 'label2') else 3\n",
    "        if not plot_gbp or not plot_hm:\n",
    "            cols-= 2 if hasattr(self, 'label2') else 1\n",
    "\n",
    "        fig,row_axes = plt.subplots(1,cols,figsize=(cols*5,5))  \n",
    "        col=0\n",
    "        size=self.xb_img.shape[-1]\n",
    "        self.xb_img.show(row_axes[col]);col+=1\n",
    "        \n",
    "        label1_title = f'1.{self.label1} {self.prob1:.3f}'\n",
    "        if plot_hm:\n",
    "            show_heatmap(self.hmap1,self.xb_img,size,row_axes[col])\n",
    "            row_axes[col].set_title(label1_title);col+=1\n",
    "        if plot_gbp:\n",
    "            row_axes[col].imshow(self.xb_grad1)\n",
    "            row_axes[col].set_axis_off()\n",
    "            row_axes[col].set_title(label1_title);col+=1\n",
    "        \n",
    "        if hasattr(self, 'label2'):\n",
    "            label2_title = f'2.{self.label2} {self.prob2:.3f}'\n",
    "            if plot_hm:\n",
    "                show_heatmap(self.hmap2,self.xb_img,size,row_axes[col])\n",
    "                row_axes[col].set_title(label2_title);col+=1\n",
    "            if plot_gbp:\n",
    "                row_axes[col].imshow(self.xb_grad2)\n",
    "                row_axes[col].set_axis_off()\n",
    "                row_axes[col].set_title(label2_title)\n",
    "        # plt.tight_layout()\n",
    "        fig.subplots_adjust(wspace=0, hspace=0)\n",
    "        # fig.savefig('data_draw/both/gradcam.png')\n",
    "\n",
    "def minmax_norm(x):\n",
    "    return (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "def scaleup(x,size):\n",
    "    scale_mult=size/x.shape[0]\n",
    "    upsampled = scipy.ndimage.zoom(x, scale_mult)\n",
    "    return upsampled\n",
    "\n",
    "# hook for Gradcam\n",
    "def hooked_backward(m,xb,target_layer,clas):\n",
    "    with hook_output(target_layer) as hook_a: #hook at last layer of group 0's output (after bn, size 512x7x7 if resnet34)\n",
    "        with hook_output(target_layer, grad=True) as hook_g: # gradient w.r.t to the target_layer\n",
    "            preds = m(xb)\n",
    "            preds[0,int(clas)].backward() # same as onehot backprop\n",
    "    return hook_a,hook_g\n",
    "\n",
    "def clamp_gradients_hook(module, grad_in, grad_out):\n",
    "    for grad in grad_in:\n",
    "        torch.clamp_(grad, min=0.0)\n",
    "        \n",
    "# hook for guided backprop\n",
    "def hooked_ReLU(m,xb,clas):\n",
    "    relu_modules = [module[1] for module in m.named_modules() if str(module[1]) == \"ReLU(inplace)\"]\n",
    "    with callbacks.Hooks(relu_modules, clamp_gradients_hook, is_forward=False) as _:\n",
    "        preds = m(xb)\n",
    "        preds[0,int(clas)].backward()\n",
    "        \n",
    "def guided_backprop(learn,xb,y):\n",
    "    xb = xb.cuda()\n",
    "    m = learn.model.eval();\n",
    "    xb.requires_grad_();\n",
    "    if not xb.grad is None:\n",
    "        xb.grad.zero_(); \n",
    "    hooked_ReLU(m,xb,y);\n",
    "    return xb.grad[0].cpu().numpy()\n",
    "\n",
    "def show_heatmap(hm,xb_im,size,ax=None):\n",
    "    if ax is None:\n",
    "        _,ax = plt.subplots()\n",
    "    xb_im.show(ax)\n",
    "    ax.imshow(hm, alpha=0.8, extent=(0,size,size,0),\n",
    "              interpolation='bilinear',cmap='magma');\n",
    "\n",
    "def get_grad_heatmap(learn,xb,y,size):\n",
    "    '''\n",
    "    Main function to get hmap for heatmap and xb_grad for guided backprop\n",
    "    '''\n",
    "    xb = xb.cuda()\n",
    "    m = learn.model.eval();\n",
    "    target_layer = m[0][-1][-1] # last layer of group 0\n",
    "    hook_a,hook_g = hooked_backward(m,xb,target_layer,y)\n",
    "    \n",
    "    target_act= hook_a.stored[0].cpu().numpy()\n",
    "    target_grad = hook_g.stored[0][0].cpu().numpy()\n",
    "    \n",
    "    mean_grad = target_grad.mean(1).mean(1)\n",
    "#     hmap = (target_act*mean_grad[...,None,None]).mean(0)\n",
    "    hmap = (target_act*mean_grad[...,None,None]).sum(0)\n",
    "    hmap = np.where(hmap >= 0, hmap, 0)\n",
    "    \n",
    "    xb_grad = guided_backprop(learn,xb,y) # (3,224,224)        \n",
    "    #minmax norm the grad\n",
    "    xb_grad = minmax_norm(xb_grad)\n",
    "    hmap_scaleup = minmax_norm(scaleup(hmap,size)) # (224,224)\n",
    "    \n",
    "    # multiply xb_grad and hmap_scaleup and switch axis\n",
    "    xb_grad = np.einsum('ijk, jk->jki',xb_grad, hmap_scaleup) #(224,224,3)\n",
    "    \n",
    "    return hmap,xb_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set params\n",
    "\n",
    "# Set batch size of images \n",
    "bs = 32  #64\n",
    "\n",
    "# set paths\n",
    "image_path = Path(\"D:/JupyterNotebook/user/bridge_crack/ml/train/\")  #(\"/content/gdrive/My Drive/Bridge_Crack_Image_Data-master/train_final/\")\n",
    "model_save_path = Path(\"D:/JupyterNotebook/user/bridge_crack/ml/models/\")  #(\"/content/gdrive/My Drive/Bridge_Crack_Image_Data-master/trained_model/\")\n",
    "\n",
    "image_path.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy, torch, random, etc\n",
    "def random_seed(seed_value, use_cuda):  \n",
    "    np.random.seed(seed_value) \n",
    "    torch.manual_seed(seed_value) \n",
    "    random.seed(seed_value) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    if use_cuda: torch.cuda.manual_seed_all(seed_value) \n",
    "\n",
    "# Set seed\n",
    "#random_seed(0,False)\n",
    "random_seed(0,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "# fastai is automatically supposed to handle image format conversions- greyscale(L), RGB\n",
    "\n",
    "# https://forums.fast.ai/t/how-to-load-images-as-grayscale/36895/6\n",
    "# google: can fastai convert greyscale images to RGB\n",
    "\n",
    "data = ImageDataBunch.from_folder(image_path, \n",
    "                                  valid_pct=0.20,\n",
    "                                  ds_tfms=get_transforms(), \n",
    "                                  size=224, \n",
    "                                  bs=bs, \n",
    "                                  num_workers=1,\n",
    "                                  seed=0).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes\n",
    "data.c\n",
    "len(data.train_ds)\n",
    "len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count no. of examples in train & validation sets \n",
    "# train set\n",
    "vc = pd.value_counts(data.train_ds.y.items, sort =False)\n",
    "vc.index = data.classes\n",
    "vc\n",
    "# ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val set\n",
    "vc = pd.value_counts(data.valid_ds.y.items, sort =False)\n",
    "vc.index = data.classes\n",
    "vc\n",
    "# ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING: Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34      #resnet50\n",
    "\n",
    "precision = Precision()\n",
    "recall = Recall()\n",
    "metrics = [accuracy,precision,recall]\n",
    "learn = cnn_learner(data, resnet34, pretrained=True, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to add other metrics\n",
    "# https://forums.fast.ai/t/f1-score-as-metric/30370/26\n",
    "# https://forums.fast.ai/t/precision-recall-understanding-averages/41019\n",
    "# https://forums.fast.ai/t/understanding-metrics-and-callbacks/28172\n",
    "\n",
    "# http://dev.fast.ai/metrics\n",
    "# there is another page of metrics under docs, & definitions are different - why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn with default model + extra 1 layer\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the basic Resnet34 model\n",
    "learn.save('resnet34_epc4_val20_stage-1')  \n",
    "learn.export(model_save_path/'resnet34_epc4_val20_stage-1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  model performance : stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(3,3), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.most_confused()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images with the highest loss (biggest mistake)\n",
    "interp.plot_top_losses(22, figsize=(18,18))\n",
    "# interp.plot_top_losses(9,heatmap=True, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find wrongly predicted images\n",
    "# https://forums.fast.ai/t/path-of-images-corresponding-to-top-losses/30506\n",
    "\n",
    "#interp.top_losses(9)\n",
    "losses,idxs = interp.top_losses(22)   # indices of wrongly predicted images\n",
    "data.valid_ds.x.items[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run GradCAM on 1st image\n",
    "x,y=data.valid_ds[264]  # put correct index here, from \"idxs\"\n",
    "x.show()\n",
    "print(y)\n",
    "\n",
    "img = x\n",
    "gcam = GradCam.from_one_img(learn,img)\n",
    "gcam.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd image\n",
    "x,y=data.valid_ds[1716]\n",
    "print(y)\n",
    "img = x\n",
    "gcam = GradCam.from_one_img(learn,img)\n",
    "gcam.plot()\n",
    "# why is it not focusing on the region that has the crack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### model training: stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unfreezing & training all layers\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(model_save_path/'resnet34_epc4_val20_stage-2.pkl')\n",
    "#learn.save(os.path.join(model_save_path,'/resnet34_nocrk6000_epc2_stage-2'))\n",
    "learn.save('resnet34_epc4_val20_stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(3,3), dpi=100)  # wrong predictions for crack reduce at the cost of no crack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('resnet34_epc4_val20_stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()\n",
    "# thisworks if \n",
    "#     i. model is loaded with ''\n",
    "#    ii. load statement ends with ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeing doc string\n",
    "doc(learn.recorder.plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model training: stage 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unfreeze & train with changing learning rates\n",
    "# we will re-load the previously built model (resnet34), & try some more epochs\n",
    "# especially if stage 2 shows similar or slightly worse performance to previous model?\n",
    "\n",
    "#learn.load(\"resnet34_epc4_val20_stage-1\")\n",
    "learn.load('resnet34_epc4_val20_stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "#learn.fit_one_cycle(4)\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(model_save_path/'resnet34_nocrk6000_epc2_stage-3.pkl')\n",
    "#learn.save(os.path.join(model_save_path,'/resnet34_nocrk6000_epc2_stage-3'))\n",
    "learn.save('resnet34_nocrk6000_epc2_stage-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model interpretation\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(3,3), dpi=100)  # wrong predictions for crack reduce at the cost of no crack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK PERFORMANCE ON NEW IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 3 model\n",
    "#learn = load_learner(model_save_path, \"resnet34_epc2_stage-1.pkl\")\n",
    "#learn = load_learner(model_save_path, \"resnet34_nocrk6000_epc2_stage-3.pkl\")\n",
    "\n",
    "# level 1 model\n",
    "learn.load('resnet34_epc4_val20_stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# predicting on a separate set, with labeled data\n",
    "# this method can be used only if the test images are directly in the \"test\" directory\n",
    "\n",
    "\n",
    "test_directory = '/content/gdrive/My Drive/Bridge_Crack_Image_Data-master/test/'\n",
    "# need to use single quotes in the above command; double quote gave I/O error\n",
    "\n",
    "images = os.listdir(test_directory)\n",
    "\n",
    "from fastai.vision import image\n",
    "pred = []\n",
    "\n",
    "for i in images:\n",
    "    img = image.open_image(test_directory+i)   # NameError: name 'image' is not defined  if image is not imported\n",
    "    pred_class,pred_idx,outputs = learn.predict(img)\n",
    "    pred.append(str(pred_class))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on a separate set, with labeled data\n",
    "# use this method if there are several folders withing test folder\n",
    "test_directory = './ml/test/'   #'/content/gdrive/My Drive/Bridge_Crack_Image_Data-master/test/'\n",
    "images = []\n",
    "\n",
    "for r, d, f in os.walk(test_directory):\n",
    "    for file in f:\n",
    "        #if file.endswith(\".docx\"):\n",
    "        images.append(os.path.join(r, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import image\n",
    "pred = []\n",
    "\n",
    "# check timestamp at start & end of predictions\n",
    "#print(datetime.now())\n",
    "start_time = datetime.now()\n",
    "\n",
    "for i in images:\n",
    "    #img = image.open_image(test_directory+i)   # NameError: name 'image' is not defined  if image is not imported\n",
    "    img = image.open_image(i)\n",
    "    pred_class,pred_idx,outputs = learn.predict(img)\n",
    "    pred.append(str(pred_class))\n",
    "\n",
    "end_time = datetime.now()\n",
    "#print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_time)\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(end_time - start_time).total_seconds()/450\n",
    "(end_time - start_time).total_seconds()/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "\n",
    "for item in images:   # can be used if images are in sub-folders within test\n",
    "#for item in os.listdir(test_directory):  # only when images are directly in \"test\"\n",
    "    if 'no' in item:\n",
    "        actual.append('no_crack')\n",
    "    if 'crack' in item:\n",
    "        actual.append('crack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "class_names = ['crack','no_crack']\n",
    "print(classification_report(actual, pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(actual,pred,labels=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(actual, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to check prediction time : how many images is this checking on?\n",
    "\n",
    "%timeit pred_class,pred_idx,outputs = learn.predict(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
